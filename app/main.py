"""
AI POC - ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ OEM ê²¬ì  ì±—ë´‡
Streamlit ë©”ì¸ ì•±
"""

import json
import time
import streamlit as st
from dotenv import load_dotenv

# .env ë¡œë“œ
load_dotenv()

from app.config import (
    APP_TITLE, APP_ICON,
    DEFAULT_SEARCH_RESULTS, DEFAULT_MAX_TOKENS, DEFAULT_TEMPERATURE,
    LLM_PRICING, SEARCH_PRICING
)
from app.providers.search import get_search_manager, SearchResult
from app.providers.llm import get_llm_manager, LLMResponse
from app.services import (
    IngredientService,
    QuoteCalculator,
    ProductSpec,
    ReferenceService,
)
from app.utils.prompt import (
    get_system_prompt,
    get_quote_system_prompt,
    build_user_prompt,
    build_extract_prompt,
    build_reference_suggestion,
    estimate_tokens
)


# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=APP_TITLE,
    page_icon=APP_ICON,
    layout="wide"
)


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "search_results" not in st.session_state:
        st.session_state.search_results = []
    if "last_metrics" not in st.session_state:
        st.session_state.last_metrics = {}
    if "quote_state" not in st.session_state:
        st.session_state.quote_state = {}
    if "last_quote" not in st.session_state:
        st.session_state.last_quote = None


def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ëª¨ë“œ ì„ íƒ
        st.subheader("ðŸ“Œ ëª¨ë“œ")
        mode = st.radio(
            "ê¸°ëŠ¥ ì„ íƒ",
            options=["OEM ê²¬ì ", "ê²€ìƒ‰ ì±—ë´‡"],
            index=0,
            help="OEM ê²¬ì : ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ê²¬ì  ê³„ì‚°\nê²€ìƒ‰ ì±—ë´‡: ì¼ë°˜ ì •ë³´ ê²€ìƒ‰"
        )

        st.divider()

        # LLM ì„ íƒ
        st.subheader("ðŸ¤– LLM")
        llm_manager = get_llm_manager()
        available_llm = llm_manager.get_available_providers()

        llm_options = ["Gemini 2.0 Flash", "GPT-5-nano", "GPT-5-mini", "GPT-4o-mini"]
        llm_provider = st.selectbox(
            "LLM Provider",
            options=llm_options,
            index=0,
            help="ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  LLM ì„ íƒ"
        )

        # LLM ìƒíƒœ ë° ê°€ê²© í‘œì‹œ
        for provider in llm_options:
            status = "âœ…" if provider in available_llm else "âŒ (í‚¤ ì—†ìŒ)"
            pricing = LLM_PRICING.get(provider, {})
            price_str = f"${pricing.get('input', 0)}/{pricing.get('output', 0)}"
            st.caption(f"{provider}: {status} - {price_str}/1M")

        st.divider()

        # ê²€ìƒ‰ API ì„ íƒ (ê²€ìƒ‰ ëª¨ë“œì¼ ë•Œë§Œ)
        if mode == "ê²€ìƒ‰ ì±—ë´‡":
            st.subheader("ðŸ” ê²€ìƒ‰ API")
            search_manager = get_search_manager()
            available_search = search_manager.get_available_providers()

            search_options = ["DDGS", "Brave", "Tavily", "Google"]
            search_provider = st.selectbox(
                "ê²€ìƒ‰ Provider",
                options=search_options,
                index=0,
                help="ê²€ìƒ‰ì— ì‚¬ìš©í•  API ì„ íƒ"
            )

            # ê²€ìƒ‰ API ìƒíƒœ í‘œì‹œ
            for provider in search_options:
                status = "âœ…" if provider in available_search else "âŒ (í‚¤ ì—†ìŒ)"
                free_limit = SEARCH_PRICING.get(provider, {}).get("free_limit", "")
                st.caption(f"{provider}: {status} - {free_limit}")

            st.divider()
        else:
            search_provider = "DDGS"

        # ê³ ê¸‰ ì„¤ì •
        with st.expander("ðŸ”§ ê³ ê¸‰ ì„¤ì •"):
            max_results = st.slider(
                "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
                min_value=1,
                max_value=10,
                value=DEFAULT_SEARCH_RESULTS
            )

            temperature = st.slider(
                "Temperature",
                min_value=0.0,
                max_value=1.0,
                value=DEFAULT_TEMPERATURE,
                step=0.1
            )

            compact_mode = st.checkbox(
                "í† í° ì ˆì•½ ëª¨ë“œ",
                value=False,
                help="í”„ë¡¬í”„íŠ¸ ì••ì¶•ìœ¼ë¡œ ë¹„ìš© ì ˆê°"
            )

            use_fallback = st.checkbox(
                "Fallback ì‚¬ìš©",
                value=True,
                help="ê²€ìƒ‰/LLM ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ API ì‹œë„"
            )

        st.divider()

        # ë©”íŠ¸ë¦­ í‘œì‹œ
        st.subheader("ðŸ“Š ë§ˆì§€ë§‰ ìš”ì²­ ë©”íŠ¸ë¦­")
        metrics = st.session_state.get("last_metrics", {})
        if metrics:
            st.metric("ì‘ë‹µ ì‹œê°„", f"{metrics.get('response_time', 0):.2f}ì´ˆ")
            st.metric("ìž…ë ¥ í† í°", metrics.get('input_tokens', 0))
            st.metric("ì¶œë ¥ í† í°", metrics.get('output_tokens', 0))
            st.metric("ì˜ˆìƒ ë¹„ìš©", f"${metrics.get('cost', 0):.6f}")
            st.caption(f"LLM: {metrics.get('llm_provider', '-')}")
        else:
            st.caption("ì•„ì§ ìš”ì²­ ì—†ìŒ")

        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ðŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.search_results = []
            st.session_state.last_metrics = {}
            st.session_state.quote_state = {}
            st.session_state.last_quote = None
            st.rerun()

        return {
            "mode": mode,
            "search_provider": search_provider,
            "llm_provider": llm_provider,
            "max_results": max_results,
            "temperature": temperature,
            "compact_mode": compact_mode,
            "use_fallback": use_fallback,
        }


def render_quick_quote_form():
    """ë¹ ë¥¸ ê²¬ì  í¼ ë Œë”ë§"""
    st.subheader("ðŸ“ ë¹ ë¥¸ ê²¬ì ")

    ingredient_svc = IngredientService()

    col1, col2 = st.columns(2)

    with col1:
        # ì›ë£Œ ì„ íƒ
        ingredients = ingredient_svc.list_all_ingredients()
        main_ingredients = [i["name"] for i in ingredients if i["category"] == "ì£¼ì›ë£Œ"]

        ingredient = st.selectbox(
            "ì£¼ì›ë£Œ",
            options=main_ingredients + ["ê¸°íƒ€ (ì§ì ‘ ìž…ë ¥)"],
            index=0
        )

        if ingredient == "ê¸°íƒ€ (ì§ì ‘ ìž…ë ¥)":
            ingredient = st.text_input("ì›ë£Œëª… ìž…ë ¥")

        # ì œí˜• ì„ íƒ
        product_types = ingredient_svc.list_product_types()
        product_type = st.selectbox("ì œí˜•", options=product_types, index=0)

        # ì£¼ì›ë£Œ ë¹„ìœ¨
        main_ratio = st.slider("ì£¼ì›ë£Œ ë¹„ìœ¨ (%)", min_value=50, max_value=100, value=80)

    with col2:
        # ê·œê²©
        gram_per_pouch = st.number_input("1í¬ë‹¹ ê·¸ëž¨ (g)", min_value=1, max_value=20, value=5)
        pouch_per_box = st.number_input("1ë°•ìŠ¤ë‹¹ í¬ìˆ˜", min_value=10, max_value=100, value=30)
        boxes = st.number_input("ì´ ë°•ìŠ¤ ìˆ˜", min_value=100, max_value=100000, value=3000, step=100)

    # ë ˆí¼ëŸ°ìŠ¤ ì œí’ˆ í‘œì‹œ
    if ingredient and ingredient != "ê¸°íƒ€ (ì§ì ‘ ìž…ë ¥)":
        ref_svc = ReferenceService(ingredient_svc)
        refs = ref_svc.get_db_references(ingredient)

        if refs:
            with st.expander("ðŸ“Œ ë ˆí¼ëŸ°ìŠ¤ ì œí’ˆ ì°¸ê³ "):
                for ref in refs:
                    ratio_str = ", ".join(f"{k} {v}%" for k, v in ref.ratio.items())
                    st.caption(f"**{ref.name}**: {ratio_str}")

    # ê²¬ì  ê³„ì‚° ë²„íŠ¼
    if st.button("ðŸ’° ê²¬ì  ê³„ì‚°", type="primary", use_container_width=True):
        if not ingredient or ingredient == "ê¸°íƒ€ (ì§ì ‘ ìž…ë ¥)":
            st.error("ì›ë£Œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        # ë¶€í˜•ì œ ìžë™ ì¶”ì²œ
        excipients = ingredient_svc.recommend_excipients(main_ratio)
        ratios = {ingredient: main_ratio, **excipients}

        # ê²¬ì  ê³„ì‚°
        spec = ProductSpec(
            product_type=product_type,
            gram_per_pouch=gram_per_pouch,
            pouch_per_box=pouch_per_box,
            boxes=boxes,
            ingredient_ratios=ratios
        )

        calc = QuoteCalculator(ingredient_svc)
        result = calc.calculate(spec)

        # ê²°ê³¼ ì €ìž¥ ë° í‘œì‹œ
        st.session_state.last_quote = result
        return result

    return None


def render_quote_result(result):
    """ê²¬ì  ê²°ê³¼ ë Œë”ë§"""
    if not result:
        return

    st.success("ê²¬ì ì´ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ë©”ì¸ ìš”ì•½
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ì˜ˆìƒê¸ˆì•¡", f"{result.total_cost:,}ì›")
    with col2:
        st.metric("ë°•ìŠ¤ë‹¹ ë‹¨ê°€", f"{result.price_per_box:,}ì›")
    with col3:
        st.metric("ì´ ì›ë£ŒëŸ‰", f"{result.product_spec.total_kg:.1f}kg")

    # ìƒì„¸ ë‚´ì—­
    with st.expander("ðŸ“‹ ìƒì„¸ ê²¬ì ì„œ", expanded=True):
        calc = QuoteCalculator()
        st.text(calc.format_quote(result))

    # ê²½ê³  ë©”ì‹œì§€
    if result.warnings:
        for warning in result.warnings:
            st.warning(f"âš ï¸ {warning}")


def render_chat_interface(settings: dict):
    """ëŒ€í™”í˜• ê²¬ì  ì¸í„°íŽ˜ì´ìŠ¤"""
    st.subheader("ðŸ’¬ ëŒ€í™”í˜• ê²¬ì ")
    st.caption("ìžì—°ì–´ë¡œ ê²¬ì ì„ ìš”ì²­í•˜ì„¸ìš”. ì˜ˆ: 'ì°¨ì „ìží”¼ í™˜ 5g 30í¬ 3000ë°•ìŠ¤ ë§Œë“¤ê³  ì‹¶ì–´'")

    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ìž…ë ¥ì°½
    if prompt := st.chat_input("ê²¬ì  ìš”ì²­ì„ ìž…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ê²¬ì  ë¶„ì„ ì¤‘..."):
                answer, metrics = process_quote_query(prompt, settings)

                if answer:
                    st.markdown(answer)
                else:
                    st.error("ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                # ìƒíƒœ ì €ìž¥
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.session_state.last_metrics = metrics

        st.rerun()


def process_quote_query(query: str, settings: dict) -> tuple[str, dict]:
    """
    ê²¬ì  ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬

    Returns:
        (ë‹µë³€, ë©”íŠ¸ë¦­)
    """
    start_time = time.time()

    ingredient_svc = IngredientService()
    ref_svc = ReferenceService(ingredient_svc)
    calc = QuoteCalculator(ingredient_svc)
    llm_manager = get_llm_manager()

    # 1. LLMìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ ì‹œë„
    extract_prompt = build_extract_prompt(query)
    system_prompt = get_quote_system_prompt(compact=settings["compact_mode"])

    response = llm_manager.generate(
        prompt=extract_prompt,
        provider_name=settings["llm_provider"],
        system_prompt="JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.",
        max_tokens=500,
        temperature=0.1
    )

    # 2. ì¶”ì¶œëœ ì •ë³´ íŒŒì‹±
    try:
        # JSON ì¶”ì¶œ ì‹œë„
        content = response.content.strip()
        # ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```" in content:
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
        extracted = json.loads(content)
    except (json.JSONDecodeError, IndexError):
        extracted = {}

    # 3. ì •ë³´ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±
    answer_parts = []

    ingredient = extracted.get("ingredient")
    product_type = extracted.get("product_type")
    gram_per_pouch = extracted.get("gram_per_pouch")
    pouch_per_box = extracted.get("pouch_per_box")
    boxes = extracted.get("boxes")
    ratios = extracted.get("ratios")

    # ì •ë³´ í™•ì¸ ë©”ì‹œì§€
    if ingredient:
        answer_parts.append(f"**ì›ë£Œ**: {ingredient}")

        # ë ˆí¼ëŸ°ìŠ¤ ì œí’ˆ ì¡°íšŒ
        refs = ref_svc.get_db_references(ingredient)
        if refs and not ratios:
            ref_list = []
            for ref in refs:
                ratio_str = ", ".join(f"{k} {v}%" for k, v in ref.ratio.items())
                ref_list.append({"name": ref.name, "ratio": ref.ratio})
            answer_parts.append("\n" + build_reference_suggestion(ingredient, ref_list))

    # ëˆ„ë½ ì •ë³´ ì§ˆë¬¸
    missing = []
    if not ingredient:
        missing.append("ì›ë£Œ")
    if not product_type:
        missing.append("ì œí˜• (í™˜/ë¶„ë§/ì •ì œ/ê³¼ë¦½)")
    if not gram_per_pouch:
        missing.append("1í¬ë‹¹ ê·¸ëž¨")
    if not pouch_per_box:
        missing.append("1ë°•ìŠ¤ë‹¹ í¬ìˆ˜")
    if not boxes:
        missing.append("ì´ ë°•ìŠ¤ ìˆ˜")

    if missing:
        answer_parts.append(f"\nì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤: **{', '.join(missing)}**")

    # ê²¬ì  ê³„ì‚° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if all([ingredient, product_type, gram_per_pouch, pouch_per_box, boxes]):
        # ë¹„ìœ¨ì´ ì—†ìœ¼ë©´ ë ˆí¼ëŸ°ìŠ¤ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        if not ratios:
            suggested_ratio = ref_svc.suggest_ratio(ingredient, main_ratio=80)
            ratios = suggested_ratio
            answer_parts.append(f"\në¹„ìœ¨ ë¯¸ì§€ì •ìœ¼ë¡œ ê¸°ë³¸ê°’ ì ìš©: {ingredient} 80%")

        # ê²¬ì  ê³„ì‚°
        spec = ProductSpec(
            product_type=product_type,
            gram_per_pouch=gram_per_pouch,
            pouch_per_box=pouch_per_box,
            boxes=boxes,
            ingredient_ratios=ratios
        )

        result = calc.calculate(spec)
        st.session_state.last_quote = result

        answer_parts.append("\n---\n")
        answer_parts.append(calc.format_quote(result))

    answer = "\n".join(answer_parts) if answer_parts else "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”."

    elapsed_time = time.time() - start_time
    metrics = {
        "response_time": elapsed_time,
        "input_tokens": response.input_tokens,
        "output_tokens": response.output_tokens,
        "total_tokens": response.total_tokens,
        "cost": response.estimated_cost,
        "llm_provider": settings["llm_provider"],
    }

    return answer, metrics


def process_search_query(query: str, settings: dict) -> tuple[str, list[SearchResult], dict]:
    """
    ê²€ìƒ‰ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬

    Returns:
        (ë‹µë³€, ê²€ìƒ‰ ê²°ê³¼, ë©”íŠ¸ë¦­)
    """
    start_time = time.time()

    # 1. ê²€ìƒ‰ ì‹¤í–‰
    search_manager = get_search_manager()
    search_results, used_search = search_manager.search(
        query=query,
        provider_name=settings["search_provider"],
        max_results=settings["max_results"],
        use_fallback=settings["use_fallback"]
    )

    # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = get_system_prompt(compact=settings["compact_mode"])
    user_prompt = build_user_prompt(
        query=query,
        search_results=search_results,
        compact=settings["compact_mode"]
    )

    # 3. LLM ë‹µë³€ ìƒì„±
    llm_manager = get_llm_manager()
    response = llm_manager.generate(
        prompt=user_prompt,
        provider_name=settings["llm_provider"],
        system_prompt=system_prompt,
        max_tokens=DEFAULT_MAX_TOKENS,
        temperature=settings["temperature"]
    )

    # 4. ë©”íŠ¸ë¦­ ê³„ì‚°
    elapsed_time = time.time() - start_time
    metrics = {
        "response_time": elapsed_time,
        "input_tokens": response.input_tokens,
        "output_tokens": response.output_tokens,
        "total_tokens": response.total_tokens,
        "cost": response.estimated_cost,
        "search_provider": used_search or settings["search_provider"],
        "llm_provider": settings["llm_provider"],
    }

    return response.content, search_results, metrics


def render_search_chatbot(settings: dict):
    """ê²€ìƒ‰ ì±—ë´‡ ì¸í„°íŽ˜ì´ìŠ¤"""
    st.subheader("ðŸ” ê²€ìƒ‰ ì±—ë´‡")

    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.search_results:
        with st.expander(f"ðŸ” ê²€ìƒ‰ ê²°ê³¼ ({len(st.session_state.search_results)}ê±´)", expanded=False):
            for i, r in enumerate(st.session_state.search_results, 1):
                st.markdown(f"""
**[{i}] [{r.title}]({r.url})**
{r.snippet[:200]}{'...' if len(r.snippet) > 200 else ''}
""")
                if i < len(st.session_state.search_results):
                    st.divider()

    # ìž…ë ¥ì°½
    if prompt := st.chat_input("ê±´ê°•ê¸°ëŠ¥ì‹í’ˆì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                answer, search_results, metrics = process_search_query(prompt, settings)

                if answer:
                    st.markdown(answer)
                else:
                    st.error("ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.session_state.search_results = search_results
                st.session_state.last_metrics = metrics

        st.rerun()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    init_session_state()

    # íƒ€ì´í‹€
    st.title(f"{APP_ICON} {APP_TITLE}")

    # ì‚¬ì´ë“œë°”
    settings = render_sidebar()

    # ëª¨ë“œì— ë”°ë¥¸ ë©”ì¸ ì˜ì—­ ë Œë”ë§
    if settings["mode"] == "OEM ê²¬ì ":
        st.caption("ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ OEM ìžë™ ê²¬ì  ì‹œìŠ¤í…œ")

        tab1, tab2 = st.tabs(["ðŸ“ ë¹ ë¥¸ ê²¬ì ", "ðŸ’¬ ëŒ€í™”í˜• ê²¬ì "])

        with tab1:
            result = render_quick_quote_form()
            if result:
                render_quote_result(result)
            elif st.session_state.last_quote:
                render_quote_result(st.session_state.last_quote)

        with tab2:
            render_chat_interface(settings)

    else:  # ê²€ìƒ‰ ì±—ë´‡
        st.caption("ê²€ìƒ‰ API + LLM ì¡°í•© í…ŒìŠ¤íŠ¸")
        render_search_chatbot(settings)


if __name__ == "__main__":
    main()
